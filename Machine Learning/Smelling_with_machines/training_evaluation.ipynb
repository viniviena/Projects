{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "renewable-receptor",
   "metadata": {},
   "source": [
    "# Training machines to smell - Part 3: Model set up, training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-circulation",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-automation",
   "metadata": {},
   "source": [
    "In this notebook code for the model set up, training and evaluation will be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-penalty",
   "metadata": {},
   "source": [
    "## 2. Models set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-interference",
   "metadata": {},
   "source": [
    "As mentioned in the project proposal, the base line model for this task (state-of-art) is random forest. Detail is not provided about the hyperparameters since it was a competition. Thus, this model will be implemented for both tasks and the results compared to the baseline result of the competition for both tasks ``task 1: predict intensity`` and ``task 2: valence and descritors``.\n",
    "\n",
    "\n",
    "Here I will implement 2 models for both tasks: Random forest and KRR. The reason for the first is that the winner of the competition used random forest (I do not know if alone or in a ensemble). The second is that it is a model of great interest (linear least squares with l2-norm regularization with the kernel trick). I will also trying using both as an ensemble by taking the average of both.\n",
    "\n",
    "Both models will be implemented via ``Scikitlearn``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-insulin",
   "metadata": {},
   "source": [
    "## 2.1 Task 1 - Predict intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-photograph",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sagemaker\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-solomon",
   "metadata": {},
   "source": [
    "Get role, session and bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "improving-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-runner",
   "metadata": {},
   "source": [
    "## Random Forest Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-award",
   "metadata": {},
   "source": [
    "For random forest, the features can be used directly as they appear, no rescaling and preprocessing is needed. So the RF will be trained using the ``X_train.csv`` and ``y_train.csv`` the way they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-independence",
   "metadata": {},
   "source": [
    "## Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('task1/rf_train'):\n",
    "    os.mkdir('task1/rf_train')\n",
    "    \n",
    "if not os.path.isdir('task1/rf_val'):\n",
    "    os.mkdir('task1/rf_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-economics",
   "metadata": {},
   "source": [
    "Copying files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "copyfile(\"task1/X_train.csv\", \"task1/rf_train/X_train.csv\")\n",
    "copyfile(\"task1/y_train.csv\", \"task1/rf_train/y_train.csv\")\n",
    "copyfile(\"task1/X_ldb.csv\", \"task1/rf_train/X_ldb.csv\")\n",
    "copyfile(\"task1/y_ldb.csv\", \"task1/rf_train/y_ldb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'task1'\n",
    "train_folder = 'rf_train'\n",
    "val_folder = 'rf_val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-strength",
   "metadata": {},
   "source": [
    "Creating variable with path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(prefix, train_folder)\n",
    "val_path = os.path.join(prefix, val_folder)\n",
    "print(train_path)\n",
    "print('\\n')\n",
    "print(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-tuesday",
   "metadata": {},
   "source": [
    "Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(train_path, key_prefix = train_path)\n",
    "val_input = sagemaker_session.upload_data(val_path, key_prefix = val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-guide",
   "metadata": {},
   "source": [
    "I just createad this two variables so I did not had to upload several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = 's3://sagemaker-us-east-1-004057822769/task1/rf_train'\n",
    "val_input = 's3://sagemaker-us-east-1-004057822769/task1/rf_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input,'\\n',val_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-frost",
   "metadata": {},
   "source": [
    "## Launching training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-ferry",
   "metadata": {},
   "source": [
    "Instantiating the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "train_fname = 'train_rf.py'\n",
    "script_dir = os.path.join(prefix, 'source_sklearn')\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "rf = SKLearn(output_path = output_path,\n",
    "    source_dir = script_dir,\n",
    "    entry_point = train_fname,\n",
    "    framework_version = FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    role=role,\n",
    "    metric_definitions=[\n",
    "                   {'Name': 'validation r_mean', 'Regex': 'r_mean for validation set is: ([0-9.]+).*$'}\n",
    "                ],\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-arrival",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit({'train':train_input, 'validation':val_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-aviation",
   "metadata": {},
   "source": [
    "Instantiating a predictor object with ``deploy`` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = rf.deploy(instance_type='ml.c5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-montgomery",
   "metadata": {},
   "source": [
    "Calculating task 1 metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ldb = pd.read_csv('task1/X_ldb.csv')\n",
    "y_ldb = pd.read_csv('task1/y_ldb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(np.ravel(X_ldb.iloc[:, 1:].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-longer",
   "metadata": {},
   "source": [
    "Defining function to calculate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1_metric(y_true, y_pred, label = 'INTENSITY/STRENGTH'):\n",
    "    \"\"\" Calculate DREAM challenge metric for intensity target for random forest model\n",
    "        \n",
    "        y_true: pandas dataframe with two columns: subject # and intensity values\n",
    "        y_pred: 1D numpy array with predictions.\n",
    "        label: string with the column name that holds intensity values in y_true\n",
    "        return: tuple (all_r, mean(all_r)). The first is a list with 49 Pearson coefficients\n",
    "        the second is the average of these values.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_r = [] #Initialize an empty dictionary \n",
    "    individual_ids = y_true.loc[:,'subject #'].unique() #retrieve subject ids {1,...,49}\n",
    "    \n",
    "    #loop through subject ids\n",
    "    for ind in individual_ids: \n",
    "        ind_df = y_true.loc[y_true['subject #'] == ind, [label]] #dataframe with individual id \"ind\" and intensity\n",
    "        ind_indexes = ind_df.index.to_list() # retrieve ind_df indices\n",
    "        \n",
    "        y_ind = ind_df.values #transform dataframe in a numpy array\n",
    "        y_pred_new = y_pred[ind_indexes] #get rows in predictions array filtered with ind_indexes\n",
    "        \n",
    "        r_ind = np.corrcoef(x = y_ind, y = y_pred_new, rowvar = False)[0,1] #calculate Pearson coefficient\n",
    "        \n",
    "        all_r.append(r_ind) #Append Pearson to the list of Pearsons [r1,r2,...,r49]\n",
    "        \n",
    "    return all_r, np.mean(all_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r, mean_r = task_1_metric(y_ldb, y_pred, label = 'INTENSITY/STRENGTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-addiction",
   "metadata": {},
   "source": [
    "## Launching hyperparameter tunning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Hyperparameter Tuner\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    'min_samples_leaf': IntegerParameter(2, 8),\n",
    "    'min_samples_split': IntegerParameter(4, 16),\n",
    "    'estimators': IntegerParameter(30, 70)                    \n",
    "                        }\n",
    "\n",
    "# create Optimizer\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator = rf,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='validation r_mean',\n",
    "    metric_definitions=[\n",
    "                   {'Name': 'validation r_mean', 'Regex': 'r_mean for validation set is: ([0-9.]+).*$'}\n",
    "                ],\n",
    "    max_jobs = 10,\n",
    "    max_parallel_jobs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer.fit({'train':train_input, 'validation':val_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuner results in a df\n",
    "results = Optimizer.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = Optimizer.analytics().dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['estimators', 'min_samples_leaf', 'min_samples_split', 'FinalObjectiveValue', 'TrainingJobName']\n",
    "results[cols].to_csv('task1/rf_tunning.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-architect",
   "metadata": {},
   "source": [
    "Now, I will simply attach the training job with highest performance to the estimator called ``rf_best``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('task1/rf_tunning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.to_latex(index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = results.loc[results['FinalObjectiveValue'] == results['FinalObjectiveValue'].max(), 'TrainingJobName'].values[0]\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "train_fname = 'train_rf.py'\n",
    "script_dir = os.path.join(prefix, 'source_sklearn')\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "rf_best = SKLearn(output_path = output_path,\n",
    "    source_dir = script_dir,\n",
    "    entry_point = train_fname,\n",
    "    framework_version = FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    role=role,\n",
    "    metric_definitions=[\n",
    "                   {'Name': 'validation r_mean', 'Regex': 'r_mean for validation set is: ([0-9.]+).*$'}\n",
    "                ],\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-snowboard",
   "metadata": {},
   "source": [
    "### Deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-philip",
   "metadata": {},
   "source": [
    "Attaching the job to the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_attached = rf_best.attach(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-mouse",
   "metadata": {},
   "source": [
    "Instantiating a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = rf_attached.deploy(instance_type='ml.c5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-stephen",
   "metadata": {},
   "source": [
    "Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "recreational-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('task1/X_test.csv')\n",
    "y_test = pd.read_csv('task1/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-opportunity",
   "metadata": {},
   "source": [
    "Splitting the data in small chuncks to avoid excessive run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_X = np.split(X_test.iloc[:, 1:].values[0:3300,:], 10)\n",
    "last_x = X_test.iloc[:, 1:].values[3300:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([predictor.predict(x) for x in split_X])\n",
    "y_pred2 = predictor.predict(last_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-hawaiian",
   "metadata": {},
   "source": [
    "final vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predf = np.concatenate((y_pred , y_pred2), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-representative",
   "metadata": {},
   "source": [
    "Calculating challenge metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r, mean_r = task_1_metric(y_test, y_predf, label = 'INTENSITY/STRENGTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean pearson is', mean_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-forestry",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-compression",
   "metadata": {},
   "source": [
    "For the KRR, I will have to used the preprocessed data to fit this model since the original feature space is too large for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-monthly",
   "metadata": {},
   "source": [
    "## Upload data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "serious-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'task1'\n",
    "folder = 'krr_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sized-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1/krr_train\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(prefix, folder)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regulated-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = sagemaker_session.upload_data(path, key_prefix = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "honest-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-004057822769/task1/krr_train\n"
     ]
    }
   ],
   "source": [
    "print(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "convenient-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = 's3://sagemaker-us-east-1-004057822769/task1/krr_train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-marketplace",
   "metadata": {},
   "source": [
    "## Launching training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-slope",
   "metadata": {},
   "source": [
    "Instantiating the estimator. Now with a function ``create_model()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "marked-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(FRAMEWORK_VERSION = \"0.23-1\", train_fname = 'train_krr.py', script_dir = os.path.join(prefix, 'source_sklearn'),  output_path = 's3://{}/{}'.format(bucket, prefix)):\n",
    "    \"\"\" Creates an scikitlearn custom estimator\n",
    "        \n",
    "        FRAMEWORK_VERSION: a string that refers to scikitlearn version\n",
    "        train_fname: sring with train file name.\n",
    "        script_dir: string with directory where train_fname is located\n",
    "        output_path: string with location on s3 bucket where model artifacts will be saved\n",
    "        return: Estimator object\n",
    "    \"\"\"\n",
    "\n",
    "    model = SKLearn(output_path = output_path,\n",
    "                source_dir = script_dir,\n",
    "                entry_point = train_fname,\n",
    "                framework_version = FRAMEWORK_VERSION,\n",
    "                instance_type=\"ml.m4.xlarge\",\n",
    "                role=role,\n",
    "                metric_definitions=[\n",
    "                   {'Name': 'validation r_mean', 'Regex': 'r_mean for validation set is: ([0-9.]+).*$'}\n",
    "                ],\n",
    "                sagemaker_session=sagemaker_session)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hearing-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sized-congress",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-16 21:33:58 Starting - Starting the training job...\n",
      "2021-03-16 21:34:21 Starting - Launching requested ML instancesProfilerReport-1615930438: InProgress\n",
      ".........\n",
      "2021-03-16 21:35:44 Starting - Preparing the instances for training......\n",
      "2021-03-16 21:36:44 Downloading - Downloading input data...\n",
      "2021-03-16 21:37:24 Training - Downloading the training image..\u001b[34m2021-03-16 21:37:38,432 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-03-16 21:37:38,435 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-16 21:37:38,446 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2021-03-16 21:37:44 Training - Training image download completed. Training in progress.\u001b[34m2021-03-16 21:37:45,858 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-16 21:37:45,874 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-16 21:37:45,891 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-16 21:37:45,902 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-03-16-21-33-58-512\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-16-21-33-58-512/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_krr\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_krr.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_krr.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_krr\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-16-21-33-58-512/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-03-16-21-33-58-512\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-16-21-33-58-512/source/sourcedir.tar.gz\",\"module_name\":\"train_krr\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_krr.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train_krr.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\n",
      "2021-03-16 21:39:56 Uploading - Uploading generated training model\u001b[34mr_mean for validation set is: 0.141147061779464\u001b[0m\n",
      "\u001b[34m2021-03-16 21:39:55,027 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-03-16 21:40:26 Completed - Training job completed\n",
      "ProfilerReport-1615930438: NoIssuesFound\n",
      "Training seconds: 201\n",
      "Billable seconds: 201\n"
     ]
    }
   ],
   "source": [
    "krr.fit({'train':s3_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-brazil",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "potential-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Hyperparameter Tuner\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "def hypertuner(model, hyperparameter_ranges):\n",
    "        \"\"\" Creates an optimizer object \n",
    "        \n",
    "        model: Estimator object to use\n",
    "        hyperparameter_ranges: dictionary with parameter names as keys and their ranges and data types\n",
    "        return: Optimizer object\n",
    "        \n",
    "    \"\"\"\n",
    "    # create Optimizer\n",
    "    Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator = model,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='validation r_mean',\n",
    "    metric_definitions=[\n",
    "                   {'Name': 'validation r_mean', 'Regex': 'r_mean for validation set is: ([0-9.]+).*$'}\n",
    "                ],\n",
    "    max_jobs = 10,\n",
    "    max_parallel_jobs = 5)\n",
    "    \n",
    "    return Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-recognition",
   "metadata": {},
   "source": [
    "Instantiating the hypertuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "special-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0.01, 0.1),\n",
    "    'gamma': ContinuousParameter(0.1, 1)                  \n",
    "                        }\n",
    "krr_optimizer = hypertuner(krr, hyperparameter_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-soundtrack",
   "metadata": {},
   "source": [
    "Fitting hypertunner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "thirty-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "krr_optimizer.fit({'train':s3_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "greatest-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuner results in a df\n",
    "results = krr_optimizer.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = krr_optimizer.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "healthy-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['alpha', 'gamma', 'FinalObjectiveValue', 'TrainingJobName']\n",
    "results[cols].to_csv('task1/krr_tunning.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-edinburgh",
   "metadata": {},
   "source": [
    "Exporting as latex for build report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "willing-tuner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{rrrl}\\n\\\\toprule\\n    alpha &  gamma &  FinalObjectiveValue &                                TrainingJobName \\\\\\\\\\n\\\\midrule\\n 0.032118 &    0.1 &             0.226011 &  sagemaker-scikit-lea-210316-2150-014-c240c60f \\\\\\\\\\n 0.030319 &    0.1 &             0.226011 &  sagemaker-scikit-lea-210316-2150-015-a6028516 \\\\\\\\\\n 0.079896 &    0.1 &             0.226005 &  sagemaker-scikit-lea-210316-2150-010-1aaf4551 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by = ['FinalObjectiveValue'], ascending = False)[cols][0:3].to_latex(index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-mobility",
   "metadata": {},
   "source": [
    "### Deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-messaging",
   "metadata": {},
   "source": [
    "Retrieving job name with the highest final objective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = results.loc[results['FinalObjectiveValue'] == results['FinalObjectiveValue'].max(), 'TrainingJobName'].values[0]\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "presidential-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-department",
   "metadata": {},
   "source": [
    "Attaching training job to estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aggressive-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-16 22:09:33 Starting - Preparing the instances for training\n",
      "2021-03-16 22:09:33 Downloading - Downloading input data\n",
      "2021-03-16 22:09:33 Training - Training image download completed. Training in progress.\n",
      "2021-03-16 22:09:33 Uploading - Uploading generated training model\n",
      "2021-03-16 22:09:33 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "krr_best = krr.attach(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-recipient",
   "metadata": {},
   "source": [
    "Instantiating predictor and deploying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "requested-leisure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = krr_best.deploy(instance_type='ml.c5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-hybrid",
   "metadata": {},
   "source": [
    "Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "popular-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('task1/krr_train/test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "warming-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data.iloc[:, 0:2]\n",
    "X_test = test_data.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-canon",
   "metadata": {},
   "source": [
    "Splitting the input o avoid excessive runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "forced-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_X = np.split(X_test.values[0:3300,:], 10)\n",
    "last_x = X_test.values[3300:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "boring-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([predictor.predict(x) for x in split_X])\n",
    "y_pred2 = predictor.predict(last_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "nuclear-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "suited-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predf = np.concatenate((y_pred , y_pred2), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-thumbnail",
   "metadata": {},
   "source": [
    "Creating new metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "complicated-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1_metric_krr(y_true, y_pred, label = 0):\n",
    "    \"\"\" Calculate DREAM challenge metric for intensity target for kernel ridge regressor\n",
    "        \n",
    "        y_true: pandas dataframe with two columns without names.\n",
    "        y_pred: 1D numpy array with predictions.\n",
    "        label: int with the column index that holds intensity values in y_true\n",
    "        return: tuple (all_r, mean(all_r)). The first is a list with 49 Pearson coefficients\n",
    "        the second is the average of these values.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_r = [] #Initialize an empty dictionary \n",
    "    col_index = 1 #column that contatin intensity values\n",
    "    individual_ids = y_true.iloc[:, col_index].unique() #retrieve subject ids {1,...,49}\n",
    "    \n",
    "     #loop through subject ids\n",
    "    for ind in individual_ids:\n",
    "        ind_df = y_true.loc[y_true.iloc[:, col_index] == ind].iloc[:, label] #dataframe with individual id \"ind\" and intensity\n",
    "        ind_indexes = ind_df.index.to_list() # retrieve ind_df indices as a list\n",
    "        \n",
    "        y_ind = ind_df.values #transform dataframe in a numpy array\n",
    "        y_pred_new = y_pred[ind_indexes] #get rows in predictions array filtered with ind_indexes\n",
    "        \n",
    "        r_ind = np.corrcoef(x = y_ind, y = y_pred_new, rowvar = False)[0,1] #calculate Pearson coefficient\n",
    "        \n",
    "        all_r.append(r_ind) #Append Pearson to the list of Pearsons [r1,r2,...,r49]\n",
    "        \n",
    "    return all_r, np.mean(all_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "classified-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r, mean_r = task_1_metric_krr(y_test, y_predf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "persistent-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3774739351413951"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-yorkshire",
   "metadata": {},
   "source": [
    "## 2.1 Task 2 - Predict valence and odor descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-roller",
   "metadata": {},
   "source": [
    "## Upload data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intense-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('task2/rf_train'):\n",
    "    os.mkdir('task2/rf_train')\n",
    "    \n",
    "if not os.path.isdir('task2/rf_val'):\n",
    "    os.mkdir('task2/rf_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-underground",
   "metadata": {},
   "source": [
    "Copying features and target files to task2/rf foldes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yellow-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'task2/rf_val/y_ldb.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile(\"task1/X_train.csv\", \"task2/rf_train/X_train.csv\")\n",
    "copyfile(\"task2/y_train.csv\", \"task2/rf_train/y_train.csv\")\n",
    "copyfile(\"task1/X_ldb.csv\", \"task2/rf_val/X_ldb.csv\")\n",
    "copyfile(\"task2/y_ldb.csv\", \"task2/rf_val/y_ldb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "editorial-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'task2'\n",
    "train_folder = 'rf_train'\n",
    "val_folder = 'rf_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dressed-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task2/rf_train\n",
      "\n",
      "\n",
      "task2/rf_val\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(prefix, train_folder)\n",
    "val_path = os.path.join(prefix, val_folder)\n",
    "print(train_path)\n",
    "print('\\n')\n",
    "print(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twelve-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(train_path, key_prefix = train_path)\n",
    "val_input = sagemaker_session.upload_data(val_path, key_prefix = val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "completed-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-004057822769/task2/rf_train \n",
      " s3://sagemaker-us-east-1-004057822769/task2/rf_val\n"
     ]
    }
   ],
   "source": [
    "print(train_input , '\\n', val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "supposed-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('task2/source_sklearn'):\n",
    "    os.mkdir('task2/source_sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-florence",
   "metadata": {},
   "source": [
    "## Preparing Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-cotton",
   "metadata": {},
   "source": [
    "Instantiating estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "conventional-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = create_model(FRAMEWORK_VERSION = \"0.23-1\", train_fname = 'train_rf.py', \n",
    "             script_dir = os.path.join(prefix, 'source_sklearn'),  \n",
    "             output_path = 's3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-ideal",
   "metadata": {},
   "source": [
    "Defining task 2 metric function to be used in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "driven-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining metric function\n",
    "def task_2_metric(y_true, y_pred):\n",
    "        \"\"\" Calculate DREAM challenge metric for valence and odor descritors target for\n",
    "        random forest\n",
    "        \n",
    "        y_true: pandas dataframe with two columns without names.\n",
    "        y_pred: 1D numpy array with predictions.\n",
    "        return: float with the sum of r_int and r_dec\n",
    "    \"\"\"\n",
    "    r_val = [] #Initialize an empty dictionary to hold pearson for valence\n",
    "    r_odors = [] #Initialize an empty dictionary to hold pearson for 19 odor descriptors\n",
    "    \n",
    "    col_name = 'subject #' #Column that contains subject ids\n",
    "    individual_ids = y_true.loc[:,col_name].unique() #retrieve subject unique ids {1,...,49}\n",
    "    \n",
    "    #Valence loop-----------------------------------------\n",
    "     #loop through subject ids\n",
    "    for ind in individual_ids:\n",
    "        ind_df = y_true.loc[y_true[col_name] == ind, ['VALENCE/PLEASANTNESS']] #dataframe with individual id \"ind\" and valence\n",
    "        ind_indexes = ind_df.index.to_list() # retrieve ind_df indices\n",
    "        \n",
    "        epsilon = np.random.randn(len(ind_df))*0.0001 #Small random value to add to columns with all zeros\n",
    "        \n",
    "        y_ind = ind_df.values #transform dataframe in a numpy array\n",
    "        \n",
    "        #Conditional to check inf the variability is 0\n",
    "        if np.var(y_ind) == 0.0:\n",
    "            y_ind += abs(epsilon) #Add small random number if True\n",
    "            \n",
    "        y_pred_new = y_pred[ind_indexes, 0] #get rows in predictions array filtered with ind_indexes\n",
    "        \n",
    "        r_ind = np.corrcoef(x = y_ind, y = y_pred_new, rowvar = False)[0,1] #calculate Pearson coefficient\n",
    "        \n",
    "        r_val.append(r_ind) #Append Pearson to the list of Pearsons [r1,r2,...,r49]\n",
    "        \n",
    "    r_mean_val = np.mean(r_val) #Calculate mean pearson\n",
    "    \n",
    "    #Odors loop-------------------------------------------------------\n",
    "    \n",
    "    for col in range(2,21): #Column indexes of odor descriptors values\n",
    "        print(col)\n",
    "        for ind in individual_ids:\n",
    "            \n",
    "            ind_df = y_true.loc[y_true[col_name] == ind].iloc[:, col] #indexes for individual\n",
    "            ind_indexes = ind_df.index.to_list() #Transform indexes to list\n",
    "            \n",
    "            epsilon = np.random.randn(len(ind_df))*0.0001 #Random noise to avoid error with columns with 0 variance\n",
    "            \n",
    "            y_ind = ind_df.values  #Get true outputs for individuals\n",
    "            \n",
    "            if np.var(y_ind) == 0.0: #Conditional to check inf the variability is 0\n",
    "                y_ind += abs(epsilon) #Add small random number if True\n",
    "                \n",
    "            y_pred_new = y_pred[ind_indexes, col-1] #Get predictions for individuals\n",
    "        \n",
    "            r_ind = np.corrcoef(x = y_ind, y = y_pred_new, rowvar = False)[0,1] #Calculate correlation\n",
    "        \n",
    "            r_odors.append(r_ind) #append values to r_odors list\n",
    "    print(r_mean_val) # Logging\n",
    "    print(np.mean(r_odors)) #Logging\n",
    "    return r_mean_val +  np.mean(r_odors) #Return the sum of the two metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-aaron",
   "metadata": {},
   "source": [
    "## Running training job to check it is correctly configured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-missile",
   "metadata": {},
   "source": [
    "fitting estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "premier-former",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-17 19:55:45 Starting - Starting the training job...ProfilerReport-1616010945: InProgress\n",
      "..............................\n",
      "2021-03-17 20:01:14 Starting - Launching requested ML instances..................\n",
      "2021-03-17 20:04:19 Starting - Preparing the instances for training...........................\n",
      "2021-03-17 20:08:42 Downloading - Downloading input data.........\n",
      "2021-03-17 20:10:23 Training - Downloading the training image..\u001b[34m2021-03-17 20:10:32,621 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-03-17 20:10:32,624 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-17 20:10:32,636 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2021-03-17 20:10:55 Training - Training image download completed. Training in progress.\u001b[34m2021-03-17 20:10:40,660 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-17 20:10:40,675 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-17 20:10:40,688 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-17 20:10:40,699 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-03-17-19-55-45-630\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-17-19-55-45-630/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_rf\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_rf.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_rf.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_rf\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-17-19-55-45-630/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-03-17-19-55-45-630\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-004057822769/sagemaker-scikit-learn-2021-03-17-19-55-45-630/source/sourcedir.tar.gz\",\"module_name\":\"train_rf\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_rf.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train_rf.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34m2021-03-17 20:14:41,597 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-03-17 20:14:47 Uploading - Uploading generated training model\n",
      "2021-03-17 20:14:47 Completed - Training job completed\n",
      "Training seconds: 367\n",
      "Billable seconds: 367\n"
     ]
    }
   ],
   "source": [
    "rf2.fit({'train':train_input, 'validation':val_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-shark",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-sword",
   "metadata": {},
   "source": [
    "Instantiating ``optimizer`` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "olympic-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'min_samples_leaf': IntegerParameter(2, 15),\n",
    "    'min_samples_split': IntegerParameter(4, 50),\n",
    "    'estimators': IntegerParameter(20, 70)                    \n",
    "                        }\n",
    "\n",
    "rf_optimizer = hypertuner(rf2, hyperparameter_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-conservation",
   "metadata": {},
   "source": [
    "fitting optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "rf_optimizer.fit({'train':train_input, 'validation':val_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-mainland",
   "metadata": {},
   "source": [
    "retrieving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "indian-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuner results in a df\n",
    "results = rf_optimizer.analytics().dataframe()\n",
    "while results.empty:\n",
    "    time.sleep(1)\n",
    "    results = rf_optimizer.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-screening",
   "metadata": {},
   "source": [
    "saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "immediate-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['estimators', 'min_samples_leaf', 'min_samples_split', 'FinalObjectiveValue', 'TrainingJobName']\n",
    "results[cols].to_csv('task2/rf_tunning.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "hired-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = results[cols].sort_values(by = ['FinalObjectiveValue'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "educated-jacob",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingJobName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.461973</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-001-bbda7e89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.459336</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-010-8871460c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.456904</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-006-216d11e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.454657</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-004-54abbf48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.454008</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-005-06d22863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.451621</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-008-989509a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.450059</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-007-0dc852b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.445999</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-003-656288f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.445827</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-002-0ffa76ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.441251</td>\n",
       "      <td>sagemaker-scikit-lea-210317-2022-009-d2ce40e0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimators  min_samples_leaf  min_samples_split  FinalObjectiveValue  \\\n",
       "9        68.0              12.0               17.0             0.461973   \n",
       "0        68.0               3.0                4.0             0.459336   \n",
       "4        64.0              10.0               41.0             0.456904   \n",
       "6        37.0              12.0               17.0             0.454657   \n",
       "5        48.0               9.0               35.0             0.454008   \n",
       "2        34.0               4.0               23.0             0.451621   \n",
       "3        23.0              12.0               14.0             0.450059   \n",
       "7        62.0              15.0                5.0             0.445999   \n",
       "8        63.0              14.0               30.0             0.445827   \n",
       "1        40.0               9.0               47.0             0.441251   \n",
       "\n",
       "                                 TrainingJobName  \n",
       "9  sagemaker-scikit-lea-210317-2022-001-bbda7e89  \n",
       "0  sagemaker-scikit-lea-210317-2022-010-8871460c  \n",
       "4  sagemaker-scikit-lea-210317-2022-006-216d11e3  \n",
       "6  sagemaker-scikit-lea-210317-2022-004-54abbf48  \n",
       "5  sagemaker-scikit-lea-210317-2022-005-06d22863  \n",
       "2  sagemaker-scikit-lea-210317-2022-008-989509a4  \n",
       "3  sagemaker-scikit-lea-210317-2022-007-0dc852b2  \n",
       "7  sagemaker-scikit-lea-210317-2022-003-656288f0  \n",
       "8  sagemaker-scikit-lea-210317-2022-002-0ffa76ab  \n",
       "1  sagemaker-scikit-lea-210317-2022-009-d2ce40e0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-scholarship",
   "metadata": {},
   "source": [
    "Transforming in latex code for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "listed-tyler",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{rrrrl}\\n\\\\toprule\\n estimators &  min\\\\_samples\\\\_leaf &  min\\\\_samples\\\\_split &  FinalObjectiveValue &                                TrainingJobName \\\\\\\\\\n\\\\midrule\\n       68.0 &              12.0 &               17.0 &             0.461973 &  sagemaker-scikit-lea-210317-2022-001-bbda7e89 \\\\\\\\\\n       68.0 &               3.0 &                4.0 &             0.459336 &  sagemaker-scikit-lea-210317-2022-010-8871460c \\\\\\\\\\n       64.0 &              10.0 &               41.0 &             0.456904 &  sagemaker-scikit-lea-210317-2022-006-216d11e3 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results.head(3).to_latex(index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-middle",
   "metadata": {},
   "source": [
    "### Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "about-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-scikit-lea-210317-2022-001-bbda7e89\n"
     ]
    }
   ],
   "source": [
    "job_name = results.loc[results['FinalObjectiveValue'] == results['FinalObjectiveValue'].max(), 'TrainingJobName'].values[0]\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "baking-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_best = create_model(FRAMEWORK_VERSION = \"0.23-1\", train_fname = 'train_rf.py', \n",
    "             script_dir = os.path.join(prefix, 'source_sklearn'),  \n",
    "             output_path = 's3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-console",
   "metadata": {},
   "source": [
    "Attaching best model job name to estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "generic-curtis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-17 20:43:03 Starting - Preparing the instances for training\n",
      "2021-03-17 20:43:03 Downloading - Downloading input data\n",
      "2021-03-17 20:43:03 Training - Training image download completed. Training in progress.\n",
      "2021-03-17 20:43:03 Uploading - Uploading generated training model\n",
      "2021-03-17 20:43:03 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "rf2_best = rf2_best.attach(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-fourth",
   "metadata": {},
   "source": [
    "Instantiating a predictor with ``Estimator.deploy()`` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "national-hindu",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = rf2_best.deploy(instance_type='ml.c5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-above",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "major-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('task1/X_test.csv')\n",
    "y_test = pd.read_csv('task2/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "mobile-going",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992, 4870)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-wonder",
   "metadata": {},
   "source": [
    "Splitting data to avoid excessive run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "recovered-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_X = np.split(X_test.iloc[:, 1:].values[0:2990,:], 10)\n",
    "last_x = X_test.iloc[:, 1:].values[2990:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-jungle",
   "metadata": {},
   "source": [
    "Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "distinguished-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([predictor.predict(x) for x in split_X])\n",
    "y_pred2 = predictor.predict(last_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-motel",
   "metadata": {},
   "source": [
    "Reshaping ``y_pred`` to a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "supreme-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-accounting",
   "metadata": {},
   "source": [
    "Concatenating the first 2990 predictions with the last ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "informal-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predf = np.concatenate((y_pred , y_pred2), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aggregate-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992, 20) (2992, 21)\n"
     ]
    }
   ],
   "source": [
    "print(y_predf.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-audience",
   "metadata": {},
   "source": [
    "Calculating metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "mature-accommodation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "0.35621828233417147\n",
      "0.1711582233673975\n"
     ]
    }
   ],
   "source": [
    "mean_r = task_2_metric(y_test, y_predf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "sunset-charge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5273765057015689"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
