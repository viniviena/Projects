{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-killing",
   "metadata": {},
   "source": [
    "   # Training machines to smell - Part 1: Data acquisition and feature generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-retro",
   "metadata": {},
   "source": [
    "## Project overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-answer",
   "metadata": {},
   "source": [
    "This project is dedicated to create machine learning models for predicting odor properties of molecules from the DREAM Olfactory Challenge. In this first notebook, the data acquisition and feature generation is discussed. For the sake of organization, the training procedure and exploratory data analysis will be implemented in other notebook files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-inventory",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-pipeline",
   "metadata": {},
   "source": [
    "The cell below downloads the dataset from [this repository](https://github.com/dream-olfaction/olfaction-prediction). The repo contains data used for DREAM Olfaction Prediction Challenge. The data collected from the experiments were splitted into 3 smaller datasets. In the competition, the first was intended to be used for training the machine learning algorithm, the second to evaluate the performance of the competitors half-way the end of the competition and the third to create the final rank and rank competitors. \n",
    "\n",
    "All three data set are in the ``data`` directory. The first dataset is in the ``TrainSet.txt`` file, the second in the ``leaderboard_set.txt`` and the third in the ``TextSet.txt``.\n",
    "\n",
    "I have not cloned the directory to the jupyter notebook instance since there are a lot of additional files that I will not use. Instead, I will load them directly from the github repo using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quick-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd==1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.1\n",
      "    Uninstalling xlrd-2.0.1:\n",
      "      Successfully uninstalled xlrd-2.0.1\n",
      "Successfully installed xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applied-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2df(file_path):\n",
    "    ''' Reads a raw file from a github online repository and store it in a pandas dataframe.\n",
    "    \n",
    "        param file_path: a string that points to a .txt file in a github repo (It has to be a raw file)\n",
    "        return: Pandas dataframe with the content inside the file\n",
    "    '''\n",
    "    df = pd.read_table(file_path) #reades .txt file format\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "living-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining online github directory path and file names\n",
    "data_ondir = 'https://raw.githubusercontent.com/dream-olfaction/olfaction-prediction/master/data/'\n",
    "train_file = 'TrainSet.txt' #train set file name\n",
    "ldboard_file = 'LBs1.txt'   #Leaderbord file name subchallenge 1\n",
    "#ldboard_file = 'leaderboard_set.txt'\n",
    "test_file = 'TestSet.txt'\n",
    "\n",
    "#Joining strings to compose the path that points to the files\n",
    "train_path = os.path.join(data_ondir, train_file)\n",
    "ldboard_path = os.path.join(data_ondir, ldboard_file)\n",
    "test_path = os.path.join(data_ondir, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overhead-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the files from the repo and storing in a dataframe\n",
    "train_df = txt2df(train_path)\n",
    "ldb_df = txt2df(ldboard_path)\n",
    "test_df = txt2df(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-viewer",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "* The first column (“Compound Identifier”) contains the PubChem Compound Identification, an identifier for a unique chemical structure.\n",
    "*  The second column (“Odor”) contains a synonym for the chemical. Be aware that there are many synonyms. For identifying the odor, the CID and not the odor name should be used.\n",
    "*  The third column (\"replicate\") indicates whether the stimulus is part of the 20 stimuli that were tested twice.\n",
    "* The fourth column (“intensity”) indicates whether the data is for the odor at high intensity (lower dilution of that odor) or at low intensity (higher dilution of that odor).\n",
    "* The fifth column (“dilution”) contains the dilution of the odor. Each odor is presented at two different dilutions. Weak odors are diluted less than strong odors, so that the low dilution of all the odors has approximately equal intensity. The high dilution of all the odors also has approximately equal intensity. (Equi-intensity is only very roughly approximated. Some of the chemicals have no smell at all, so they obviously cannot be diluted to be equi-intense with others.)\n",
    "* The sixth column (“subject #”) contains a subject identifier, a number from 1 to 49.\n",
    "\n",
    "Columns 7-27 contain perceptual data that the 49 subjects provided during smell testing. Before subjects rated a given odor, they were asked if they could smell anything when they sniffed the odor. If they indicated that they smelled nothing, the intensity rating was automatically set to “0” and the other ratings were left blank. Occasionally, subjects answered this first question yes, indicating that they could smell something, but then proceeded to rate the intensity as “0”. These subjects also completed all the other ratings. This is why you will find that in most cases when the intensity rating is “0,” there are no other data, but in a few cases you will find a complete data set even if the intensity was rated “0.”\n",
    "\n",
    "* The seventh column (“Intensity/Strength”) contains perceptual data about how intense or strong the smell was perceived by the subjects. Subjects used a scale from 0-100 where 100 is “extremely strong” and 0 is “extremely weak”.\n",
    "* The eighth column (“Valence/Pleasantness”) contains perceptual data about how pleasant or unpleasant the smell was perceived by the subjects. Subjects used a scale from 0-100 where 100 is “extremely pleasant” and 0 is “extremely unpleasant”.\n",
    "* Columns 9-27 contain data in which subjects matched their perception of how the odor smelled to a standard list of 19 perceptual descriptors: bakery, sweet, fruit, fish, garlic, spices, cold, sour, burnt, acid, warm, musky, sweaty, ammonia/ruinous, decayed, wood, grass, flower, chemical\n",
    "\n",
    "*Subjects used a scale from 0-100 where 100 is “very much” and 0 is “not at all”.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-praise",
   "metadata": {},
   "source": [
    "##  Feature generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-thriller",
   "metadata": {},
   "source": [
    "The datasets do not provide informative data about the molecules except its commonly used name and identifier. One way to gather more information about them is by using their PubChem Compound Identification and lookup their features in the PubChem database.\n",
    "\n",
    "Let's just make some definitions before diving into molecular features\n",
    "\n",
    "* ``molecules`` are  a collection of atoms connected by chemical bonds in a 3-D arrangement. (That's my definition)\n",
    "\n",
    "So, we need a set of informations to fully define a molecule: The position of the atoms with respect to a set of coordinates (x,y,z), which atom are in each position and how they connect with their neighboors (bonds). Basically, we are encoding molecules using symbolic entities -- real numbers (position of atoms) and letters (C for carbon, O for oxygen). \n",
    "\n",
    "\n",
    "However, this is not the only way to model molecules with symbolic entities. There is a famous symbolic representation of molecules called SMILES (simplified molecular-input line-entry system). Molecules are represented with lined ASCII strings which aim to define a molecule from its features (atoms' type, geometric distribution and connectivity). The rules to model molecules with SMILES can found [here](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system). Just to give a concrete example, water can be represented as \"O\" or by \"[H]O[H]\". One of the characteristics of this representation is that a single molecule can have multiple SMILES representation, but a given SMILES identify one and only molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-tongue",
   "metadata": {},
   "source": [
    "\n",
    "We can go from symbolic entities to useful numeric representations! The repository from which I collected the data sets also contain [Dragon descriptors](https://match.pmf.kg.ac.rs/electronic_versions/Match56/n2/match56n2_237-248.pdf) for all the molecules! They compute numerical representations of molecules from their atomic constituents. \n",
    "These descriptors is shown to be of similar quality (statistically indistinguishable) compared with Mordred and Bitbased RDKit fingerprints for [QSOR problems](https://arxiv.org/abs/1910.10685)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-meter",
   "metadata": {},
   "source": [
    "### Training set\n",
    "\n",
    "* In this section, the code is used to  generate features for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-story",
   "metadata": {},
   "source": [
    "**Dropping rows with NaN (null odor intensity)**\n",
    "\n",
    "``Before`` splitting the data I will deal is deal with missing entries in the data set. As the data description shows, there are missing data. The missing data are cases where the subjects could not smell anything at all in the experiment. These rows have also a 0 intensity entry. In face of that fact, inputation of missing values does not make sense. The only way to deal with it is by removing experiments where the subject was not sensitive to a particular smell at a particular dilution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "direct-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data set contains 35084 rows\n"
     ]
    }
   ],
   "source": [
    "print('Raw data set contains', train_df.shape[0], 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-beads",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-fitness",
   "metadata": {},
   "source": [
    "* Dropping rows with ``pd.DataFrame.dropna()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appropriate-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns = ['Odor', 'Replicate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "silver-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "immediate-occasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping NaN rows it has 25980 rows\n"
     ]
    }
   ],
   "source": [
    "print('After dropping NaN rows it has', train_df.shape[0], 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "turned-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 9104 experiments were removed. 25.949150609964654 %\n"
     ]
    }
   ],
   "source": [
    "print('A total of', 35084 - train_df.shape[0], 'experiments were removed.',  (1 - train_df.shape[0]/35084)*100, '%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-mandate",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-fundamental",
   "metadata": {},
   "source": [
    "* Selecting the column in the training set with molecular identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "motivated-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_df[['Compound Identifier']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-chicago",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-immigration",
   "metadata": {},
   "source": [
    "**Importing Features**\n",
    "\n",
    "Now I almost have the data in the format I want. The next step is transforming the molecular models into useful numeric representations! The repository from which I collected the data sets also contain [Dragon descriptors](https://match.pmf.kg.ac.rs/electronic_versions/Match56/n2/match56n2_237-248.pdf) for all the molecules! These descriptors is shown to be of similar quality (statistically indistinguishable) compared with Mordred and Bitbased RDKit fingerprints for [QSOR problems](https://arxiv.org/abs/1910.10685)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-restoration",
   "metadata": {},
   "source": [
    "Importing Dragon features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "absolute-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dragon1 = pd.read_table('https://raw.githubusercontent.com/dream-olfaction/olfaction-prediction/master/data/molecular_descriptors_data.txt')\n",
    "dragon2 = pd.read_excel('data/dragon descriptors for 0869 odors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "dragon = pd.concat([dragon1,dragon2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unauthorized-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dragon = dragon.iloc[:, 0:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-waterproof",
   "metadata": {},
   "source": [
    "Creating a directory to store the features as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-provider",
   "metadata": {},
   "source": [
    "Now we can create our feature matrix for training set by looking up the dragon the descriptors of the compound identifier column. Additionally, I will save both features and targets as csv files in hard disk to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "central-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('task1'):\n",
    "    os.mkdir('task1')\n",
    "if not os.path.isdir('task2'):\n",
    "    os.mkdir('task2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-going",
   "metadata": {},
   "source": [
    "* Look up  ``mol_ids`` features with ``pd.DataFrame.merge`` method. Left data frame is ``train_ids`` and right dataframe is ``dragon``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "viral-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look up\n",
    "X = train_ids[['Compound Identifier']].merge(dragon, left_on = 'Compound Identifier', \n",
    "                                                  right_on = 'CID').iloc[:,1:]\n",
    "#print('number of features is', X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distinguished-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features is 4870\n"
     ]
    }
   ],
   "source": [
    "print('number of features is', X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-least",
   "metadata": {},
   "source": [
    "Labels for task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "double-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = train_df.loc[:,['subject #', 'INTENSITY/STRENGTH']]\n",
    "y_1.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacterial-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25980, 4870) (25980, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-rental",
   "metadata": {},
   "source": [
    "Labels for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sustainable-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2drop = ['Compound Identifier', 'Intensity','Dilution','INTENSITY/STRENGTH']\n",
    "y_2 = train_df.drop(columns = cols2drop)\n",
    "y_2.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impressed-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject #', 'VALENCE/PLEASANTNESS', 'BAKERY', 'SWEET', 'FRUIT', 'FISH',\n",
       "       'GARLIC', 'SPICES', 'COLD', 'SOUR', 'BURNT', 'ACID', 'WARM', 'MUSKY',\n",
       "       'SWEATY', 'AMMONIA/URINOUS', 'DECAYED', 'WOOD', 'GRASS', 'FLOWER',\n",
       "       'CHEMICAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-taste",
   "metadata": {},
   "source": [
    "After the look up, some features are missing in the training set. The following cells drop rows with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "provincial-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a boolean mask for NaN values\n",
    "rows_mask = X.isnull().any(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dried-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the mask both in X and y dataframes\n",
    "X, y_1, y_2  = X.loc[~rows_mask], y_1.loc[~rows_mask], y_2.loc[~rows_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "confidential-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25762, 4870) (25762, 2) (25762, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y_1.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-alfred",
   "metadata": {},
   "source": [
    "Saving ``X``, ``y_1`` and ``y_2`` to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dried-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('task1/X_train.csv', index = False)\n",
    "y_1.to_csv('task1/y_train.csv', index = False)\n",
    "y_2.to_csv('task2/y_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "invisible-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning memory\n",
    "train_df = None\n",
    "X = y_1 = y_2 =  None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-auction",
   "metadata": {},
   "source": [
    "###  Leaderboard and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-might",
   "metadata": {},
   "source": [
    "In my analysis, I will use the leaderboard set as my validation set eventhough this is was not what happened during the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-hearts",
   "metadata": {},
   "source": [
    "**Leaderboard**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-garage",
   "metadata": {},
   "source": [
    "**Dropping rows with NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "specific-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#oID', 'individual', 'descriptor', 'value'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldb_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-pharmacy",
   "metadata": {},
   "source": [
    "NaN mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "interracial-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_mask = ldb_df.isna().value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "academic-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldb_df = ldb_df[~na_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-command",
   "metadata": {},
   "source": [
    "Unpivoting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "matched-chapel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = ldb_df.pivot_table(index=['#oID','individual'], columns='descriptor', aggfunc= lambda x: x)\n",
    "df2.columns = df2.columns.droplevel().rename(None)\n",
    "df2 = df2.reset_index().dropna(axis = 0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reverse-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ldb = df2[['individual', 'INTENSITY/STRENGTH']]\n",
    "cols2 = ['individual','VALENCE/PLEASANTNESS', 'BAKERY', 'SWEET', 'FRUIT', 'FISH',\n",
    "       'GARLIC', 'SPICES', 'COLD', 'SOUR', 'BURNT', 'ACID', 'WARM', 'MUSKY',\n",
    "       'SWEATY', 'AMMONIA/URINOUS', 'DECAYED', 'WOOD', 'GRASS', 'FLOWER',\n",
    "       ' CHEMICAL']\n",
    "\n",
    "y2_ldb = df2.loc[:,cols2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "patent-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(y2_ldb.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rental-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_ldb.reset_index(inplace = True, drop = True)\n",
    "y2_ldb.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-kinase",
   "metadata": {},
   "source": [
    "Features look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "discrete-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features look up\n",
    "\n",
    "X_ldb = df2[['#oID']].merge(dragon, left_on = '#oID', right_on = 'CID').iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-judgment",
   "metadata": {},
   "source": [
    "Mask for Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "moved-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a boolean mask for NaN values\n",
    "rows_mask = X_ldb.isnull().any(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-harassment",
   "metadata": {},
   "source": [
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "trained-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the mask both in X and y dataframes\n",
    "X_ldb, y1_ldb, y2_ldb = X_ldb.loc[~rows_mask],y1_ldb.loc[~rows_mask], y2_ldb.loc[~rows_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-danger",
   "metadata": {},
   "source": [
    "Saving to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "useful-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ldb.to_csv('task1/X_ldb.csv', index = False, header = True)\n",
    "y1_ldb.to_csv('task1/y_ldb.csv', index = False, header = True)\n",
    "y2_ldb.to_csv('task2/y_ldb.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-arthur",
   "metadata": {},
   "source": [
    "**Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mature-radio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Compound Identifier', 'Odor', 'Replicate', 'Intensity', 'Dilution',\n",
       "       'subject #', 'INTENSITY/STRENGTH', 'VALENCE/PLEASANTNESS', 'BAKERY',\n",
       "       'SWEET', 'FRUIT', 'FISH', 'GARLIC', 'SPICES', 'COLD', 'SOUR', 'BURNT',\n",
       "       'ACID', 'WARM', 'MUSKY', 'SWEATY', 'AMMONIA/URINOUS', 'DECAYED', 'WOOD',\n",
       "       'GRASS', 'FLOWER', 'CHEMICAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-romania",
   "metadata": {},
   "source": [
    "Features look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "industrial-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features look up\n",
    "X_test = test_df[['Compound Identifier']].merge(dragon, left_on = 'Compound Identifier', right_on = 'CID').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-gambling",
   "metadata": {},
   "source": [
    "Targets dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "continental-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test = test_df[['INTENSITY/STRENGTH','subject #']]\n",
    "\n",
    "y2_test = test_df[['subject #','VALENCE/PLEASANTNESS', 'BAKERY', 'SWEET', 'FRUIT', 'FISH',\n",
    "       'GARLIC', 'SPICES', 'COLD', 'SOUR', 'BURNT', 'ACID', 'WARM', 'MUSKY',\n",
    "       'SWEATY', 'AMMONIA/URINOUS', 'DECAYED', 'WOOD', 'GRASS', 'FLOWER',\n",
    "       'CHEMICAL']]\n",
    "\n",
    "y1_test.reset_index(inplace = True, drop = True)\n",
    "y2_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "micro-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3381, 4870) (3381, 2) (3381, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y1_test.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ordered-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a boolean mask for NaN values\n",
    "rows_mask = X_test.isnull().any(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecological-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the mask both in X and y dataframes\n",
    "X_test = X_test[~rows_mask]\n",
    "y1_test = y1_test[~rows_mask]\n",
    "y2_test = y2_test[~rows_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "independent-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a boolean mask for NaN values in the target set\n",
    "y2_row_mask = y2_test.isnull().any(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lightweight-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the mask both in X and y dataframes\n",
    "X_test = X_test[~y2_row_mask]\n",
    "y1_test = y1_test[~y2_row_mask]\n",
    "y2_test = y2_test[~y2_row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "inappropriate-chosen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992, 4870) (2992, 2) (2992, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y1_test.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-battlefield",
   "metadata": {},
   "source": [
    "Saving files to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "israeli-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('task1/X_test.csv', index = False, header = True)\n",
    "y1_test.to_csv('task1/y_test.csv', index = False, header = True)\n",
    "y2_test.to_csv('task2/y_test.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
